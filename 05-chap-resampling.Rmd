# Robustness of Multivariate Regime Detection Measures to Varying Data Quality and Quantity Using Resampling {#resampling}
```{r cache = TRUE, echo=FALSE, warning=FALSE, eval=TRUE, message=FALSE, results="hide"}
# Chunk defaults
# require(knitr)
knitr::opts_chunk$set(cache = TRUE, cache.path = "_cache/", message = FALSE, warning=FALSE, eval=TRUE, echo=FALSE, error=FALSE, fig.align='center', out.width = "85%")
# IF ON MAC:
if(get_os()!="windows") figDir <- here::here("chapterFiles/resampling/figsCalledInDiss/")
if(get_os()=="windows") figDir <- here::here("chapterFiles/resampling/figsCalledInDiss//")
loadFig<-function(fn){paste0(figDir,fn,".png")}
```
## Introduction 
Ecological systems have many unpredictable and variably interacting components [@jorgensen_new_2011]. Methods for analyzing these complex systems, e.g. Dynamic Bayesian Networks, network models, and food webs are designed to handle these complexities, yet require data- and knowledge-intensive models. Although ecological data collection and data management techniques are improving [@lasorte2018opportunities], the aforementioned approaches to modeling and understanding complex system are often infeasible in ecosystem research and management [@clements_including_2016]. 

A growing concern with anthropogenic impacts on the environment has increased the demand for mathematical and statistical techniques that capture these dynamics. These often undesirable changes in the structure or functioning of ecological systems are often referred to as *regime shifts*, *regime changes*, *state change*, *abrupt change*, etc. [@andersen_ecological_2009] . A yet-unattained goal of ecological research and management is to reach a point where these methods can predict impending regime shifts in real-time and with high confidence. Ideally, ecological regime shift detection methods (hereafter, regime detection measures) would require little knowledge of the intrinsic drivers of the system, and the users of the method would not be required to know if and where a regime shift occurred in the data. 

Despite the suite of regime detection measures in the environmental and ecological research literatures, they are not used in ecological management. We can describe the current state of regime detection measures as being either system specific (i.e., the method is not system agnostic) or not. Methods of the latter type are convenient in that they can be applied across various system and data types, but the results of these analyses require some degree of subjective interpretation [@clements2018indicators; *c.f.* @batt2013changes]. Efforts to develop and/or improve regime detection measures that do not require such subjectivity will aid the advance of regime detection measures research and application. 

Current efforts to improve regime detection measures may be stunted by the lack of application beyond simple and/or theoretical (toy) systems data. Like most statistical and mathematical approaches, the evolution of many regime detection measures begins with application to theoretical data, followed by application to empirical data. Current applications of regime detection measures to empirical, ecological data are largely limited to data describing populations [@anderson_community_1999;@alheit_synchronous_2005; @deyoung_regime_2008], climatic, marine, and Paleolithic regime shifts [@spanbauer_prolonged_2014; @kong2017hydrological; @yang_10_2006], with few applications to terrestrial data [*c.f.* @bahlai2015shifts; @sundstrom2017detecting]. Although testing the performance and inference boundaries of theoretical and simple systems is important, they are of little use to ecosystem managers if they are not proven to be easily and reliably applicable to their system. Additionally, regime detection measures should be capable of handling empirical ecological data, which are often sparse, noisy, and irreguarly sampled..

Ecological systems data is expensive to capture, and has large  process variation and observation errors. This variability reduces data quality and quantity, limiting the numerical tools for identifing trends and changes in the system [@thrush2009forecasting]. Some methods, new and old, proposed as regime detection measures are purported to handle the data limitation and quality issues inherent in ecological data, and minimize subjective decisions for choosing state variables and interpreting results. For example, variable reduction techniques, e.g. principal components analysis [@rodionov_application_2005; @andersen_ecological_2009; @reid_global_2016], clustering algorithms [@weijerman2005regime;@weissman2016predicting], an index of variance [@brock_variance_2006],  and Fisher Information [@cabezas_towards_2002; @fath_exergy_2004; @karunanithi_detection_2008] were introduced as methods which collapse the system into a single indicator of ecological regime shifts. Although these methods have been used on empirical ecological systems data, their robustness to empirical data quality and quantity have yet to be examined. 

In this Chapter I examine the influence of observation and process errors on the inference obtained from select multivariable regime detection measures. There are three major objectives:  
1. Identify the effects of data quality on regime detection measure inference.  
2. Identify the effects of data quantity on regime detection measure inference. 
3. Explore the relative performance of velocity (described in Chapter \@ref(velocity)) to the above mentioned methods under multiple scenarios.   

This Chapter provides baseline relative performance estimates of select, multivariable regime detection measures under various scenarios of data quality and quantity. The results from this Chapter inform the practical ecologist of the potential limitations to consider when applying these regime detection measures to their data, and has potential to inform the data collection process. Additionally, the software accompanying this Chapter allows the end user to implement these methods on this diatom system, a toy system, or their own data.

## Data and Methodology
### Study system and data  
I used paleodiatom time series from a freshwater system in North America (Foy Lake, present day Montana) that apparently underwent rapid shifts in algal community dynamics at multiple points in time. This data comes from a single soil core sample, from which the relative abundances of 109 diatom species were identified at  768 observations (time points) over $\approx7,000$ years (Figure \@ref(fig:origDat). Althouh the soil core was sampled at regular distances, the soil accumulation process is not necessarily linear over time, resulting in irregularly-sampled observations (i.e., time elapsed between sampling points differs varies; see Figure \@ref(fig:timeElapsed)). The data were published in @spanbauer_prolonged_2014 and can be downloaded at the publisher's website.

```{r origDat, fig.align='center', out.width = "65%",  echo=FALSE,  fig.cap="Relative abundances of the diatom species in Foy Lake over the time period."}
knitr::include_graphics(loadFig("origDataRelAbundance"))
```

```{r timeElapsed, fig.align='center', out.width = "65%", echo=FALSE, fig.cap="The amount of time elapsed between observations."}
knitr::include_graphics(loadFig("timeElapsed"))
```

### Regime detection measures
Fewer model-free regime detection metrics exist than do model-based metrics (Chapter \@ref(rdmReview)) and of these, only a few are suggested for multivariable data. Here, I compare the results for three regime detection metrics that are model-free and can handle multivariable data: velocity (Chapter \@ref(velocity)), the Variance Index [@brock_variance_2006] and Fisher Information [@fath_regime_2003]. I chose the Variance Index, as this is one of the more widely applied multivariate, model-free regime detection measures, and has been shown to, in some empirical data, identify regime shifts *post hoc*. I introduced the velocity in Chapter \@ref(velocity) as a new, potential regime detection metric. As this is the first time it has been used for such a purpose, including it in this approach allows us to further identify potential flaws with the method, but also to gain some baseline estimates of its relative performance. In Chapter \@ref(fiGuide) I presented the Fisher Information metric as it is used in detecting ecological regime shfits, and discuss the situations under which it may or may not be a good metric. 


#### Velocity ($v$) 
In Chapter \@ref(velocity), I describe a new method, __velocity__, $v$, as a potential dimension reduction and regime detection method. First introduced by @fath_regime_2003 as one of multiple steps in calculating their variant of Fisher Information, velocity calculates the cumulative sum of the square root of the sum of the squared change in all state variables over a period of time (Eq. \@ref(eq:velocityEq)). Steps for calculating this metric are described in detail in Chapters \@ref(fiGuide) and \@ref(velocity).  

\begin{equation}
\begin{array}{rcr}
\Delta s_i = \sqrt{\sum_{j=1}^{n} (x_{i,j} -x_{i-1, j})^2}
s_k =  \sum_{i=2}^{k}\Delta{s_i}
2\leq k \leq n
v =\frac{\Delta s}{\Delta t}  
\end{array}
(\#eq:velocityEq)
\end{equation}

#### Variance Index  
The Variance Index was introduced by @brock_variance_2006, and is simply defined as the maximum eigenvalue of the covariance matrix of the system over some period (window) of time. The Variance Index (also called Variance Indicator) was originally applied to a modelled system [@brock_variance_2006], and has since been applied to empirical data [@spanbauer_prolonged_2014; @sundstrom2017detecting]. Although rising variance has been shown to manifest prior to abrupt shifts in some empirical systems data  [@van2005implications;@brock_variance_2006], the Variance Index, which is intended for multivariate data,  appears most useful when the system exhibits a discontinuous (non-linear)  shift [@brock_variance_2006].

#### Fisher Information    
Fisher Information ($I$) is essentially the area under the curve of the acceleration to the fourth degree ($s''^4$) divided by the squared velocity ($s'^2$; also referred to as $v$ in Chapter \@ref(velocity)) of the distance travelled by the system, $s$ over some period of time ($T$), and is given in Eq. \@ref(eq:fiDerivs2):  

\begin{equation}   
    I = \frac{1}{T} \int_0^T dt\left[\frac{s''^2}{s'^4}\right]^2 \\  
  (\#eq:fiDerivs2)  
\end{equation} 

I describe this method in complete detail in Chapter \@ref(fiGuide).

#### Using moving window analysis to calculate Fisher Information and Variance Index
Unlike $velocity$, the Variance Index and Fisher Information are calculated using moving window analysis. That is, over the entire time series, $T^*$, these metrics are calculated within multiple windows of time, $T$. In this approach, all state variables, $x_i$, are used to inform the calculations (of Variance Index and Fisher Information) over a time interval, $T$, where $T$ is the length in [time] units of the time interval and satisfies the following condition: $2\leq T < (T^*-1)$. If $T = T^*-1$, then only a single value of the metric will be calculated for entire time series, which does not allow for any estimate of change. 

When using these metrics in the context of identifying abrupt changes in ecological systems data across $T*$, it is ideal the value of $T$ meets the following conditions: $3 < T \ll T^*-1$. The length of a time window dictates the number of calculations one can obtain over $T^*$, such that the number of potential metric calulations increases as $\frac{T}{\ T^*}$ decreases. Previous applications of moving window analyses to calculate Fisher Information found that at least eight observations (time points) should be used [citation]. 

An additional parameter is required when conducting moving window analyses: the number of time points by which the window advances. In order to maximize the data, I advance the window at a rate of one time unit. However, it is important to note that because these data are not sampled annually and the because the window always advances by a single time unit, the number of observations included in each calculation will not be the same. If fewer than 5 observations are in a window, I did not calculate metrics, advancing the window forward. 
I assigned the calcuated values of Fisher Information and Variance Index within each moving window to the __end__ (the last time unit) of the moving window. In temporal analyses, assigning the value[which value] to any other point in time (e.g., the beginning or the middle) muddles the interpretation of the metric over $T^*$. Also note that this method has the potential to result in calculating a metric for all integers between $0.20 T^*$ and $T^*$.

### Simulating data quality and quantity issues using resampling techniques 
Using a resampling approach I calculated the regime detection measures over different scenarios simulating data quality and data quantity issues common to ecological data anlaysis. The scenarios are categorized as *observations* and *species*. The observations scenario simulates a loss of temporal observations (decreasing the number of times the system was observed), and the species scenario simulates a loss of information about the system by removing some proportion of the species. The loss of temporal observations and the loss of species were examined at three proportions: $\textbf{P} = [0.25, 0.50, 0.75, 1.00]$, where $\textbf{P}$ is the proportion of species and time points **retained** for analysis. For example, when $\textbf{P} = 0.25$, a random selection of $25\%$ of the species are retained for analysis in the species scenario. I resampled the data over $10,000$ iterations ($N_{samp}$) for each scenario and $\textbf{P}$ combination. Note that because when $\textbf{P} = 1.00$, all data are retained. Therefore, no resampling was conducted at this level because only a single metric (e.g. Velocity) value is possible.



### Comparing regime detection measures 
Interpretation of the regime detection measures used in this analysis are currently limited to visual inspection. Therefore, I limit inference in this study largely to the impact of data loss on the variability with a regime detection measure (i.e. how robust is the measure to data loss). It is important to not only identify the influence of data quality and quantity on the performance of individual regime detection metrics, but also to somehow relate these qualities. I visually inspect the relatve performance of these metrics by comparing the coefficient of variation of the resampled samples for the results of resampling method ($\textbf{M}$; species, observations) and sampling percentage ($\textbf{P}$; 25%, 50%, 75%) combination for each metric (FI, VI, $v$). The coefficient of variation measures provides a relative measure of the variability in the estimated metric across resampled samples as $100\frac{\sigma}{\mu}$, where $\sigma$ is the standard deviation and $\mu$ is the mean value. 

I observed the distributions of the CV [get rid of the error to mean ratio, confuses the issue] to identify potential flaws in the metrics should data quality or quantity ($\textbf{M}$, $\textbf{P}$) decrease. First, within a value of $\textbf{P}$ a low error to mean ratio (CV) indicates that the metric value is similar across the resampled samples ($N_{samp}=10,000$). The efficacy of the metric should be questioned as CV$\rightarrow 1$, and perahps even abandoned as CV$\gg1$. Next, we can examine how the distribution of CV changes within $\textbf{M}$ and across $\textbf{P}$. As we increase $\textbf{P}$, we are increasing the volume of data we are feeding the metric. Intuitively, we can assume that as we add more data (volume), we are supplying the metric with more *information*, theoretically increasing the signal-to-noise ratio. Following this logic, we should expect the distribution of CV to generally decrease in mean CV value and also become less variable (less dispersion around the mean CV). A visual examination of the distribution of CV across $\textbf{P}$ and within $\textbf{M}$ was suffcient to achieve inference regarding the quality of these metrics upon data loss and lessened quality.

## Results 
### Velocity 

### Variance Index

### Fisher Information is highly sensitive to information loss  



```{r fiResamp, out.width = "55%",  echo=FALSE,  fig.cap="Mean Fisher Information (FI) and associated 95% confidence intervals over 10,000 iterations using the observations (top panel) and species (bottom panel) resampling methods. Red line indicates the value of FI when **M** and **P** = 100%."}
knitr::include_graphics(loadFig("FI_observations_ribboned_facetByProb")) # observations
knitr::include_graphics(loadFig("FI_species_ribboned_facetByProb")) # species
```
```{r fiRegimes, out.width = "85%",  echo=FALSE,  fig.cap="Mean Fisher Information (FI) and associated 95% confidence intervals over 10,000 iterations using the observations (top panel) and species (bottom panel) resampling methods. Red line indicates the value of FI when **M** and **P** = 100%."}
knitr::include_graphics(loadFig(""))
```
```{r fiCV, out.width = "85%",  echo=FALSE,  fig.cap="Density plot of the coefficient of variation (CV) as a percentage (%) of the Fisher Information resampled samples (10,000 iterations). Densities are drawn based on all values of CV, but values >100% are not printed."}
knitr::include_graphics(loadFig("FI_cvDensity"))
```

It is difficult to visually analyze any value of the Fisher Information withn individual time series, as the values range from $\approx 0$ to $10^15$ (Fig. \@ref(fig:fiResamp)). Therefore, I visualize the Fisher Information values within subsets of the time series data  (Fig. \@ref(fig:fiRegimes)). Under all $\textbf{M}-\textbf{P}$ scenarios the standard deviation of FI far exceeded the mean value of FI (Fig. \@ref(fig:fiCV)). When we resample 25% and 50% of the species the ratio of mean Fisher Information to standard deviation of Fisher Information  is always $\gg 1$ (i.e, not pictured in Fig. \@ref(fig:fiCV)). The high variation in FI values across resampled iterations and high dispersion within $\textbf{M}-\textbf{P}$ combinations (Fig. \@ref(fig:fiCV))) suggests Fisher Information will not produce similar trends when we lose or distort the data collected.


## Discussion 
The primary results from this study confirm the sensitivity of regime detection metrics to data quantity and quality. Previous studies of the robustness of various methods have found that varinace (standard deviation, coefficient of variation) are unreliable measures of 'regime shifts' under numerous conditions. 

```{r loessEx, out.width = "85%",  echo=FALSE,  fig.cap="Local regression (loess) smoothing of a dominant species in the paleodiatom community, \textit{Anomoeoneis costata} varies with the span parameter, making it difficult to justify smoothing the data prior to calculating various regime detection metrics."}
knitr::include_graphics(loadFig("FI_cvDensity"))
```

### On data detrending and scaling 
If and how to manipulate the original data prior to calculating various regime detection methods is an important consideration, and a line of research that has not yet been fully explored. Although most of the multivariate methods identified in the literature review do not require data conforms to a specific distribution, how th results of these methods can vary as we change the quality and characteristics of the original data [@michener2012ecoinformatics]. In fact, since many of the methods for regime shift detection are specifically looking for changes in variance structure and autocorrelation, standardizing variances is not counterintuitive. 

Some studies detrend the original time series prior to data aggregation and calculation of regime detection metrics. I did not detrend the original data for two reasons. First, the authors of the original paper analysing this dataset [@spanbauer_prolonged_2014] did not detrend species time series. Like @spanbauer_prolonged_2014 I only scaled the original data, rather than detrending. Second, detrending a time series requires yet another subjective decision by the data analyst. For example, a "spanning" parameter must be chosen when detrending (smoothing) non-linear time series using local regression (Loess) regression (see Fig. \@ref(fig:loessEx)). Other smoothing methods are being explored for both detrending [e.g., PcR; @beck_variance_2018] and regime shift identification [e.g., generalized additive modelling; @beck_variance_2018]. Finally, this data exhibits rapid and drastic shifts in community composition *and* contains a disproprtionate amount of dominant versus non-dominant species. Consequently, most species contain more zero than non-zero observations, which makes loess smoothing difficult. Although this chapter concerns impacts of data quality and quantity based on hypothetical data collection and analytical decisions, adding yet another parameter necessitates another layer of compartive analysis. Future work studying the impact of detrending, data scaling, outlier removal, and other related decisions would be of value in understanding the efficacy of these and other regime detection measures in real-world situations.   

### Future studies should follow similar resampling, bootstreappiung, orLOO, or jackknifing appraoches to compare results upon intial introduction of the method, rather than just performing analyses on a single dataset. 
-- This may also help avoid the prosecutor's fallacy...

## Ackowledgements 
This study was conceptualized at the International Institute for Applied Systems Analysis (IIASA) as part of the Young Scholars Summer Program in 2018. I thank my IIASA program supervisors, Drs. Brian Fath and Elena Rovenskaya, for their advisement of this project and IIASA scientists Drs. Matthias Jonas, Chai Molina, Piotr Zebrowski for additional support. 
